# Docker

Установка докера и docker-compose без проблем осуществляется по официальной документации для конкретной ОС.  
Тут я хочу отразить всякие мелочи которые необходимы для работы.

### Dockefile
Кратенько о создании собственных образов.  
Более детально о директивах докерфайла смотрим в официальной документации.  

И так, чтобы создать контейнер нужно в директории проекта создать Dockefile, который будет содержать директивы для сборки контейнера приложения.  
Далее пояснение к базовым командам:
```
FROM python:3.11 <- на чем основано приложение. Контейнер с данной версией интерпретатора войдет в состав нашего контейнера. Аналогично с другими языками.

WORKDIR /app <- назначаем папку внутри контейнера в которой будет хранится приложение, и где будет происходить основной процесс сборки (копирование файлов, раздача прав и тп). 

COPY requirements.txt <- скорипить в WORKDIR файл requirements.txt Аналогично с прочими файлами и директориями. Для того чтобы не тянуть всякий мусор в контейнер, можно создать .dockerignore, куда перечислить вче то не нуждно тянуть в контейнер (аналогично .gitignore). 

RUN pip3 install -r requirements.txt <- Запустить внутри контейнера установку зависимостей. Аналогично можно запускать прочие команды, необходимые для настройки окружения (например chmod 755 . для установки прав пользователя). 

EDNPOINT ["python", "main.py"] <- то, что будет выполнятся автоматически (команды ОС) при запуске контейнера.

```

### Docker-compose (Эт чо вообще и зачем?)
Это плагин к докеру который позволяет создать некий сценарий запуска группы контейнеров.
Например, нам надо запустить python приложение которое использует redis и podtgre контейнеры одновременно. Ниже даю пример подобного конфига:  

```
version: '3.7' <- Версия плагина docker-compose. Вот чем пользуешься на момент сборки, то и указывай. 
services: <- Группа контейнеров которыми мы будем пользоваться при разворачивании приложения

  resis: <- Название произвольное, главное чтобы отражало суть. В данном случае описываем параметр контейнера redis для нашего приложения
  
    image: redis:latest <- указывается имидж контейнера с docherhub. В данном случае последняя версия redis контейнера. 
    
    command:
      - redis-server <- команда запуска сервера 
      
    env_file:
      - ./.env <- файл с переменными среды. Формат данного файла отличается от того что есть python. Нужно это помнить при настройке данного файла на сервере, откуда будет идти запуск. 
      
    restart: 
      on-failure <- что делать при падении контейнера. В данном случае если контейнер посыпался из за ошибок. 
      
    ports:
      - "6379:6379" <- указываем порты на чтение и запись соответственно. 
      
  db: <- прикручиваем postgre
    image: postgre:latest
    
    env_file:
      - ./.env
    
    volumes: <- монтируем раздел контейнера.pgdata локальная точка монтирования определяется ниже. 
      - pgdata:/var/lib/postgresql/data
    
    restart: on-failure
    
    ports:
      - "5432:5432"
  
  my_app:  <- а тут прописываем наше приложение
    build: .  <- вот так мы указываем что нужно подтянуть Dockerfile из директории откуда запускается данный скрипт. Если файл конфигурации отличается от Dockerfile или его местоположение где то за пределами текущей директории - указываем значение явно.
    
    command: sh -c "python -m my_app" <- Выполнение команды в оболочке shell позволяет нам обращаться к python через его алиас python, а не через путь до интерпретатора.
    
    env_file:
      - ./.env
    
    restart:
      always
      
    depends_on: <- указываем от каких контейнеров зависит наше приложение.
      - db
      - redis

volumes:
  pgdata:

      
```
Конфигурация описывается в формате yaml, так что следует составлять файл строго в данной нотации.    


А дальше можно через гит перетащить проект в /home/user директорию на сервере и выполнить `docker-compose up -d` в папке проекта для сборки и запуска приложения.  
Соответственно:
- выключить приложение `docker-compose down`  
- посмотреть логи (что твориться внутри контейнера) `docker logs <container_name>`  


### Запуск контейнера с Clickhouse
Создадим папку на локеле: куда будут сохранятся все данные  
`mkdir $HOME/clickhouse_database`  
Далее, запускаем контейнер в фоновом режиме  
`docker run -d --name clickhouse -p 18123:8123 -p19000:9000 --ulimit nofile=262144:262144 --volume=$HOME/clickhouse_database:/var/lib/clickhouse yandex/clickhouse-server`  
Дальше через localhost:18123/play можем поиграться с базой  
Начать можно с `select * from system.tables`
Как наигрались - выключаем  
`docker stop clickhouse` Можно гасить по CONTAINER_ID: `docker ps -a`  


### Прикольный хак для MAC (доступа из контейнера в локальный контейнер). 

Ситуация: Ваш контейнер использует к примеру СУБД. А вы хотите прицепить контейнер к локальноу СУБД развернутой в докере.  
В MAC можно в переменные среды контейнера в HOST положить вот такую строчку: `host.docker.internal`, соответственно POST указать тот, на который забинден контейнер с субд и случится магия - контейнер при запуске стукнется в локальный порт, на который забинден контейнер с субд.  
